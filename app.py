import streamlit as st
import pandas as pd
from io import BytesIO
from PIL import Image as PILImage
import requests
from openpyxl import Workbook
from openpyxl.drawing.image import Image as XLImage
from datetime import datetime
# from concurrent.futures import ThreadPoolExecutor, as_completed # ä¸¦åˆ—å‡¦ç†ã‚’ç„¡åŠ¹åŒ–

# ====== å›ºå®šè¨­å®š ======
SHOP_ID = "lilirena"     # æ¥½å¤©ã‚·ãƒ§ãƒƒãƒ—ID
MAX_WORKERS = 12         # ä¸¦åˆ—å–å¾— å›ºå®šï¼ˆã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼å»ƒæ­¢ï¼‰ -> åŒæœŸå‡¦ç†ã«ãªã£ãŸãŸã‚ã€ã“ã®å¤‰æ•°ã¯æœªä½¿ç”¨
IMG_MAX_H = 120          # ç”»åƒé«˜ã•(px)å›ºå®š
IMG_COL_WIDTH = 18       # Båˆ—ã®å¹…(æ–‡å­—æ•°)å›ºå®š
# =====================

st.set_page_config(page_title="Order Maker", page_icon="ğŸ§¾", layout="centered")

# --- NEé¢¨ã‚¹ã‚¿ã‚¤ãƒ«ï¼ˆé’ãƒœã‚¿ãƒ³ï¼†é’ã‚¿ã‚¤ãƒˆãƒ«ï¼‰ ---
st.markdown("""
<style>
:root { --ne-blue:#2a6df4; }
.block-container { max-width: 880px; }
.titlebar { font-size:22px; font-weight:800; display:flex; gap:10px; align-items:center; color:var(--ne-blue); }
.titlebar:before{content:"ğŸ“„";}
.subtle{color:#667085; font-size:13px; margin-bottom:8px;}
.card{border:1px solid #e6e9ef; border-radius:14px; padding:22px; margin:14px 0; background:#fff; box-shadow:0 2px 8px rgba(16,24,40,.04);}
.drop{border:2px dashed #d5d9e3; border-radius:12px; padding:28px; text-align:center; color:#6b7280; background:#fafbff;}
/* Streamlitã®ãƒœã‚¿ãƒ³å¼·åˆ¶ãƒ–ãƒ«ãƒ¼åŒ– */
.stButton > button {
  width: 100%; height: 52px; font-weight: 700; border-radius: 10px; font-size: 16px;
  background: var(--ne-blue) !important; color: #fff !important; border: none !important;
}
</style>
""", unsafe_allow_html=True)

st.markdown('<div class="titlebar">Order Maker</div><div class="subtle">ç™ºæ³¨æ›¸è‡ªå‹•ä½œæˆ</div>', unsafe_allow_html=True)

with st.container():
    st.markdown('<div class="card">', unsafe_allow_html=True)
    c1, c2 = st.columns(2, gap="large")
    with c1:
        st.markdown('<div class="drop">å—æ³¨ãƒ‡ãƒ¼ã‚¿</div>', unsafe_allow_html=True)
        up_orders = st.file_uploader("ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ", type=["csv"], label_visibility="collapsed", key="orders")
    with c2:
        st.markdown('<div class="drop">å•†å“ãƒã‚¹ã‚¿</div>', unsafe_allow_html=True)
        up_master = st.file_uploader("ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ", type=["xlsx","xls"], label_visibility="collapsed", key="master")
    st.markdown('</div>', unsafe_allow_html=True)

# ------- HTTP client -------
DEFAULT_HEADERS = {
    "User-Agent": ("Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
                   "AppleWebKit/537.36 (KHTML, like Gecko) "
                   "Chrome/120.0.0.0 Safari/537.36"),
    "Accept-Language": "ja,en;q=0.9",
}
session = requests.Session()
session.headers.update(DEFAULT_HEADERS)

# ------- helpers -------
def normalize_sku(s):
    if pd.isna(s): return None
    return str(s).strip().replace("ã€€"," ").lower()

def base_code_from_sku(sku: str) -> str:
    if not sku: return ""
    return str(sku).split("-")[0].strip()

def build_rakuten_url(sku: str, shop: str = SHOP_ID) -> str:
    code = base_code_from_sku(sku)
    if not code or not shop: return ""
    return f"https://item.rakuten.co.jp/{shop}/{code}/"

def pick_rakuten_image(html: str) -> str | None:
    from bs4 import BeautifulSoup
    if not html: return None
    soup = BeautifulSoup(html, "html.parser")
    for attrs in ({"property":"og:image"},{"name":"og:image"},
                  {"property":"twitter:image"},{"name":"twitter:image"},
                  {"property":"og:image:url"}):
        tag = soup.find("meta", attrs=attrs)
        if tag and tag.get("content"):
            u = tag["content"].strip()
            if u.startswith("//"): u = "https:"+u
            return u
    for sel in ["#rakutenLimitedId_ImageMain img", "#productMainImage img", "#page-body img", "img"]:
        el = soup.select_one(sel)
        if el:
            src = el.get("src") or el.get("data-src") or ""
            if src:
                if src.startswith("//"): src = "https:"+src
                return src
    return None

def download_image(image_url: str, referer: str | None = None) -> BytesIO | None:
    if not image_url: return None
    headers = DEFAULT_HEADERS.copy()
    if referer: headers["Referer"] = referer
    try:
        resp = session.get(image_url, headers=headers, stream=True, timeout=12)
        resp.raise_for_status()
        img = PILImage.open(BytesIO(resp.content))
        img.thumbnail((IMG_COL_WIDTH*5, IMG_MAX_H))
        bio = BytesIO()
        img.save(bio, format="PNG")
        bio.seek(0)
        return bio
    except Exception:
        return None

def read_orders(file) -> pd.DataFrame:
    for enc in ["cp932","utf-8-sig","utf-8"]:
        try:
            file.seek(0)
            df = pd.read_csv(file, encoding=enc)
            if {"sku","è³¼å…¥æ•°"}.issubset(df.columns):
                df["sku"] = df["sku"].apply(normalize_sku)
                df["è³¼å…¥æ•°"] = pd.to_numeric(df["è³¼å…¥æ•°"], errors="coerce").fillna(0).astype(int)
                return df
        except Exception:
            pass
    raise ValueError("å—æ³¨CSVã®åˆ—åã¯ 'sku, è³¼å…¥æ•°' ã‚’æƒ³å®šã—ã¦ã„ã¾ã™ã€‚")

# --- ç”»åƒURLå–å¾—é–¢æ•°ï¼ˆåŒæœŸå‡¦ç†ã§ä½¿ç”¨ï¼‰ ---
def fetch_image(idx: int, sku: str):
    rak_url = build_rakuten_url(sku)
    if not rak_url: return idx, "URLãªã—"
    try:
        resp = session.get(rak_url, timeout=12)
        resp.raise_for_status()
        img_url = pick_rakuten_image(resp.text)
        return idx, img_url if img_url else "ç”»åƒãªã—"
    except Exception:
        return idx, "å–å¾—å¤±æ•—"

# ====== ãƒ¡ã‚¤ãƒ³ ======
go = st.button("ç™ºæ³¨æ›¸ä½œæˆ")

if go:
    if not (up_orders and up_master):
        st.error("å—æ³¨ãƒ‡ãƒ¼ã‚¿ ã¨ å•†å“ãƒã‚¹ã‚¿ ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
        st.stop()

    try:
        orders = read_orders(up_orders)
        master = pd.read_excel(up_master)
        need = {"sku","åŸä¾¡","å•†å“URL","å•†å“åç§°","ç‰¹è¨˜äº‹é …"}
        if not need.issubset(master.columns):
            st.error(f"DBã®åˆ—åä¸è¶³: å¿…è¦ {need} / å®Ÿéš› {set(master.columns)}")
            st.stop()

        master["sku"] = master["sku"].apply(normalize_sku)
        orders_sum = orders.groupby("sku", as_index=False)["è³¼å…¥æ•°"].sum().query("è³¼å…¥æ•°>0")
        merged = orders_sum.merge(master, on="sku", how="left")

        # é€²æ—ãƒãƒ¼ï¼šç”»åƒURLå–å¾—
        prog = st.progress(0, text="ç”»åƒURLå–å¾—ä¸­â€¦")
        decided = [None]*len(merged)

        # â˜…â˜…â˜… ä¿®æ­£ç®‡æ‰€ï¼šThreadPoolExecutor ã‚’å‰Šé™¤ã—ã€åŒæœŸãƒ«ãƒ¼ãƒ—ã«ç½®ãæ›ãˆ â˜…â˜…â˜…
        total = len(merged)
        for i, (_, row) in enumerate(merged.iterrows()):
            idx, url = fetch_image(i, row.get("sku"))
            decided[idx] = url
            prog.progress(int((i + 1) * 100 / total), text=f"ç”»åƒURLå–å¾— {i + 1}/{total}")
        # â˜…â˜…â˜… ä¿®æ­£ç®‡æ‰€çµ‚äº† â˜…â˜…â˜…

        merged["ç”»åƒURL(æ±ºå®š)"] = decided
        prog.progress(100, text="ç”»åƒURLå–å¾— å®Œäº†")

        # Excelå‡ºåŠ›ï¼ˆç”»åƒåŸ‹ã‚è¾¼ã¿ï¼‰
        wb = Workbook(); ws = wb.active; ws.title = "ç™ºæ³¨æ›¸"
        headers = ["", "å†™çœŸ", "sku", "è³¼å…¥æ•°", "å˜ä¾¡",
                   "ç‰¹è¨˜äº‹é …", "å•†å“åç§°", "å•†å“URL", "å¤‰æ›´å¾ŒURL",
                   "ã‚µã‚¤ã‚º", "è‰²", "ä¸­å›½å†…é€æ–™",
                   "å˜ä¾¡", "åˆè¨ˆ", "ç™ºæ³¨æ—¥", ""]
        ws.append(headers)
        ws.column_dimensions["B"].width = float(IMG_COL_WIDTH)

        d = datetime.now(); date_str = f"{d.year}/{d.month}/{d.day}"
        ok = fail = 0

        prog2 = st.progress(0, text="Excelã«ç”»åƒã‚’åŸ‹ã‚è¾¼ã¿ä¸­â€¦")
        total_rows = len(merged)

        # â˜… ã“ã“ã‚’ iterrows ã«å¤‰æ›´ï¼ˆåˆ—åãã®ã¾ã¾ä½¿ãˆã‚‹ï¼‰
        for i, (_, row) in enumerate(merged.iterrows(), start=1):
            genka = pd.to_numeric(row.get("åŸä¾¡"), errors="coerce")
            qty = int(row.get("è³¼å…¥æ•°") or 0)
            gokei = (genka * qty) if pd.notna(genka) else None

            excel_row = ["", "", row.get("sku"), qty, genka,
                         row.get("ç‰¹è¨˜äº‹é …"), row.get("å•†å“åç§°"),
                         row.get("å•†å“URL"), "", "", "", "",
                         genka, gokei, date_str, ""]
            ws.append(excel_row)

            r_i = ws.max_row
            img_url = row.get("ç”»åƒURL(æ±ºå®š)")  # â† ãã®ã¾ã¾å‚ç…§OK
            referer = build_rakuten_url(row.get("sku"))

            bin_io = download_image(img_url, referer=referer) if (img_url and "http" in str(img_url)) else None
            if bin_io:
                try:
                    xlimg = XLImage(bin_io)
                    xlimg.anchor = f"B{r_i}"
                    ws.add_image(xlimg)
                    ws.row_dimensions[r_i].height = int(IMG_MAX_H * 0.75)
                    ok += 1
                except Exception:
                    fail += 1
            else:
                fail += 1

            prog2.progress(int(i*100/total_rows), text=f"ExcelåŸ‹ã‚è¾¼ã¿ {i}/{total_rows}")

        bio = BytesIO(); wb.save(bio); bio.seek(0)
        filename = f"ç™ºæ³¨æ›¸_{datetime.now().strftime('%Y%m%d')}_ç”»åƒåŸ‹ã‚è¾¼ã¿.xlsx"
        st.download_button("ğŸ“¥ ç™ºæ³¨æ›¸ï¼ˆç”»åƒåŸ‹ã‚è¾¼ã¿ï¼‰ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                           data=bio.getvalue(),
                           file_name=filename,
                           mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")
        st.success(f"ç”»åƒåŸ‹ã‚è¾¼ã¿ æˆåŠŸ: {ok} ä»¶ / å¤±æ•—: {fail} ä»¶")

    except Exception as e:
        st.error(f"ã‚¨ãƒ©ãƒ¼: {e}")
